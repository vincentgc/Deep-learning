{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# GAN\n",
    "## 目录\n",
    "* autoencoder\n",
    "* vae\n",
    "* gan\n",
    "\n",
    "source: https://github.com/L1aoXingyu/code-of-learn-deep-learning-with-pytorch"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 自动编码器\n",
    "自动编码器最开始是作为一种数据压缩方法，同时还可以在卷积网络中进行逐层预训练，但是随后更多结构复杂的网络，比如 resnet 的出现使得我们能够训练任意深度的网络，自动编码器就不再使用在这个方面，下面我们讲一讲自动编码器的一个新的应用，这是随着生成对抗模型而出现的，就是使用自动编码器生成数据。\n",
    "\n",
    "自动编码器的一般结构如下\n",
    "\n",
    "![](https://ws1.sinaimg.cn/large/006tNc79ly1fmzr05igw3j30ni06j3z4.jpg)\n",
    "\n",
    "由上面的图片，我们能够看到，第一部分是编码器(encoder)，第二部分是解码器(decoder)，编码器和解码器都可以是任意的模型，通常我们可以使用神经网络作为我们的编码器和解码器，输入的数据经过神经网络降维到一个编码，然后又通过另外一个神经网络解码得到一个与原始数据一模一样的生成数据，通过比较原始数据和生成数据，希望他们尽可能接近，所以最小化他们之间的差异来训练网络中编码器和解码器的参数。\n",
    "\n",
    "当训练完成之后，我们如何生成数据呢？非常简单，我们只需要拿出解码器的部分，然后随机传入 code，就可以通过解码器生成各种各样的数据\n",
    "\n",
    "![](https://ws3.sinaimg.cn/large/006tNc79ly1fmzrx3d3ygj30nu06ijs2.jpg)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "import torch\n",
    "from torch.autograd import Variable\n",
    "from torch import nn\n",
    "# 简单的自编码解码器\n",
    "class autoencoder(nn.Module):\n",
    "    def __init__(self):\n",
    "        super(autoencoder, self).__init__()\n",
    "        \n",
    "        self.encoder = nn.Sequential(\n",
    "            nn.Linear(28*28, 128),\n",
    "            nn.ReLU(True),\n",
    "            nn.Linear(128, 64),\n",
    "            nn.ReLU(True),\n",
    "            nn.Linear(64, 12),\n",
    "            nn.ReLU(True),\n",
    "            nn.Linear(12, 3) # 输出的 code 是 3 维，便于可视化\n",
    "        )\n",
    "        \n",
    "        self.decoder = nn.Sequential(\n",
    "            nn.Linear(3, 12),\n",
    "            nn.ReLU(True),\n",
    "            nn.Linear(12, 64),\n",
    "            nn.ReLU(True),\n",
    "            nn.Linear(64, 128),\n",
    "            nn.ReLU(True),\n",
    "            nn.Linear(128, 28*28),\n",
    "            nn.Tanh()\n",
    "        )\n",
    "\n",
    "    def forward(self, x):\n",
    "        encode = self.encoder(x)\n",
    "        decode = self.decoder(encode)\n",
    "        return encode, decode\n",
    "\n",
    "##使用卷积网络\n",
    "class conv_autoencoder(nn.Module):\n",
    "    def __init__(self):\n",
    "        super(conv_autoencoder, self).__init__()\n",
    "        \n",
    "        self.encoder = nn.Sequential(\n",
    "            nn.Conv2d(1, 16, 3, stride=3, padding=1),  # (b, 16, 10, 10)\n",
    "            nn.ReLU(True),\n",
    "            nn.MaxPool2d(2, stride=2),  # (b, 16, 5, 5)\n",
    "            nn.Conv2d(16, 8, 3, stride=2, padding=1),  # (b, 8, 3, 3)\n",
    "            nn.ReLU(True),\n",
    "            nn.MaxPool2d(2, stride=1)  # (b, 8, 2, 2)\n",
    "        )\n",
    "        \n",
    "        self.decoder = nn.Sequential(\n",
    "            nn.ConvTranspose2d(8, 16, 3, stride=2),  # (b, 16, 5, 5)\n",
    "            nn.ReLU(True),\n",
    "            nn.ConvTranspose2d(16, 8, 5, stride=3, padding=1),  # (b, 8, 15, 15)\n",
    "            nn.ReLU(True),\n",
    "            nn.ConvTranspose2d(8, 1, 2, stride=2, padding=1),  # (b, 1, 28, 28)\n",
    "            nn.Tanh()\n",
    "        )\n",
    "\n",
    "    def forward(self, x):\n",
    "        encode = self.encoder(x)\n",
    "        decode = self.decoder(encode)\n",
    "        return encode, decode"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "torch.Size([1, 3])\n"
     ]
    }
   ],
   "source": [
    "#简单训练\n",
    "from torchvision.datasets import MNIST\n",
    "from torchvision import transforms as tfs\n",
    "from torchvision.utils import save_image\n",
    "from torch.utils.data import DataLoader\n",
    "\n",
    "im_tfs = tfs.Compose([\n",
    "    tfs.ToTensor(),\n",
    "    tfs.Normalize([0.5, 0.5, 0.5], [0.5, 0.5, 0.5]) # 标准化\n",
    "])\n",
    "\n",
    "train_set = MNIST('/home/zlj/data/mnist', transform=im_tfs)\n",
    "train_data = DataLoader(train_set, batch_size=128, shuffle=True)\n",
    "\n",
    "#测试输出\n",
    "#net = autoencoder()\n",
    "\n",
    "conv_net = conv_autoencoder() #带卷积网络\n",
    "if torch.cuda.is_available():\n",
    "    conv_net = conv_net.cuda()\n",
    "\n",
    "x = Variable(torch.randn(1, 28*28)) # batch size 是 1\n",
    "code, _ = conv_net(x)\n",
    "print(code.shape)\n",
    "\n",
    "#定义损失函数和优化器\n",
    "criterion = nn.MSELoss(size_average=False)\n",
    "optimizer = torch.optim.Adam(net.parameters(), lr=1e-3)\n",
    "#optimizer = torch.optim.Adam(conv_net.parameters(), lr=1e-3, weight_decay=1e-5)\n",
    "\n",
    "\n",
    "\n",
    "def to_img(x):\n",
    "    '''\n",
    "    定义一个函数将最后的结果转换回图片\n",
    "    '''\n",
    "    x = 0.5 * (x + 1.)\n",
    "    x = x.clamp(0, 1)\n",
    "    x = x.view(x.shape[0], 1, 28, 28)\n",
    "    return x"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch: 20, Loss: 91.2643\n",
      "epoch: 40, Loss: 99.6230\n",
      "epoch: 60, Loss: 98.5777\n",
      "epoch: 80, Loss: 96.4058\n",
      "epoch: 100, Loss: 86.1791\n",
      "Training complete in 20m 14s\n"
     ]
    }
   ],
   "source": [
    "import time\n",
    "import os\n",
    "# 开始训练自动编码器\n",
    "since = time.time()\n",
    "for e in range(100):\n",
    "    for im, _ in train_data:\n",
    "        im = im.view(im.shape[0], -1)\n",
    "        im = Variable(im)\n",
    "        # 前向传播\n",
    "        _, output = conv_net(im)\n",
    "        loss = criterion(output, im) / im.shape[0] # 平均\n",
    "        # 反向传播\n",
    "        optimizer.zero_grad()\n",
    "        loss.backward()\n",
    "        optimizer.step()\n",
    "    \n",
    "    if (e+1) % 20 == 0: # 每 20 次，将生成的图片保存一下\n",
    "        print('epoch: {}, Loss: {:.4f}'.format(e + 1, loss.data[0]))\n",
    "        pic = to_img(output.cpu().data)\n",
    "        if not os.path.exists('./simple_autoencoder'):\n",
    "            os.mkdir('./simple_autoencoder')\n",
    "        save_image(pic, './simple_autoencoder/image_{}.png'.format(e + 1))\n",
    "time_elapsed = time.time() - since\n",
    "print('Training complete in {:.0f}m {:.0f}s'.format(\n",
    "        time_elapsed // 60, time_elapsed % 60))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<matplotlib.image.AxesImage at 0x7fdab3282b50>"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "iVBORw0KGgoAAAANSUhEUgAAAP8AAAD8CAYAAAC4nHJkAAAABHNCSVQICAgIfAhkiAAAAAlwSFlz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\nD2SK8AOZIvxApv4PUYxx+TwQRCkAAAAASUVORK5CYII=\n",
      "text/plain": [
       "<matplotlib.figure.Figure at 0x7fdb01198ed0>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "%matplotlib inline\n",
    "import matplotlib.pyplot as plt\n",
    "#随机给定一个code，看输出图像\n",
    "code = Variable(torch.FloatTensor([[1.19, -3.36, 2.06]])) # 给一个 code 是 (1.19, -3.36, 2.06)\n",
    "decode = net.decoder(code)\n",
    "decode_img = to_img(decode).squeeze()\n",
    "decode_img = decode_img.data.numpy() * 255\n",
    "plt.imshow(decode_img.astype('uint8'), cmap='gray') # 生成图片 3"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 变分自动编码器\n",
    "变分编码器是自动编码器的升级版本，其结构跟自动编码器是类似的，也由编码器和解码器构成。\n",
    "\n",
    "回忆一下，自动编码器有个问题，就是并不能任意生成图片，因为我们没有办法自己去构造隐藏向量，需要通过一张图片输入编码我们才知道得到的隐含向量是什么，这时我们就可以通过变分自动编码器来解决这个问题。\n",
    "\n",
    "其实原理特别简单，只需要在编码过程给它增加一些限制，迫使其生成的隐含向量能够粗略的遵循一个标准正态分布，这就是其与一般的自动编码器最大的不同。\n",
    "\n",
    "这样我们生成一张新图片就很简单了，我们只需要给它一个标准正态分布的随机隐含向量，这样通过解码器就能够生成我们想要的图片，而不需要给它一张原始图片先编码。\n",
    "\n",
    "一般来讲，我们通过 encoder 得到的隐含向量并不是一个标准的正态分布，为了衡量两种分布的相似程度，我们使用 KL divergence，利用其来表示隐含向量与标准正态分布之间差异的 loss，另外一个 loss 仍然使用生成图片与原图片的均方误差来表示。\n",
    "\n",
    "KL divergence 的公式如下\n",
    "\n",
    "$$\n",
    "D{KL} (P || Q) =  \\int_{-\\infty}^{\\infty} p(x) \\log \\frac{p(x)}{q(x)} dx\n",
    "$$\n",
    "## 重参数\n",
    "为了避免计算 KL divergence 中的积分，我们使用重参数的技巧，不是每次产生一个隐含向量，而是生成两个向量，一个表示均值，一个表示标准差，这里我们默认编码之后的隐含向量服从一个正态分布的之后，就可以用一个标准正态分布先乘上标准差再加上均值来合成这个正态分布，最后 loss 就是希望这个生成的正态分布能够符合一个标准正态分布，也就是希望均值为 0，方差为 1\n",
    "\n",
    "所以标准的变分自动编码器如下\n",
    "\n",
    "![](https://ws4.sinaimg.cn/large/006tKfTcgy1fn15cq6n7pj30k007t0sv.jpg)\n",
    "所以最后我们可以将我们的 loss 定义为下面的函数，由均方误差和 KL divergence 求和得到一个总的 loss\n",
    "\n",
    "```\n",
    "def loss_function(recon_x, x, mu, logvar):\n",
    "    \"\"\"\n",
    "    recon_x: generating images\n",
    "    x: origin images\n",
    "    mu: latent mean\n",
    "    logvar: latent log variance\n",
    "    \"\"\"\n",
    "    MSE = reconstruction_function(recon_x, x)\n",
    "    # loss = 0.5 * sum(1 + log(sigma^2) - mu^2 - sigma^2)\n",
    "    KLD_element = mu.pow(2).add_(logvar.exp()).mul_(-1).add_(1).add_(logvar)\n",
    "    KLD = torch.sum(KLD_element).mul_(-0.5)\n",
    "    # KL divergence\n",
    "    return MSE + KLD\n",
    "```"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "class VAE(nn.Module):\n",
    "    def __init__(self):\n",
    "        super(VAE, self).__init__()\n",
    "\n",
    "        self.fc1 = nn.Linear(784, 400)\n",
    "        self.fc21 = nn.Linear(400, 20) # mean\n",
    "        self.fc22 = nn.Linear(400, 20) # var\n",
    "        self.fc3 = nn.Linear(20, 400)\n",
    "        self.fc4 = nn.Linear(400, 784)\n",
    "\n",
    "    def encode(self, x):\n",
    "        h1 = F.relu(self.fc1(x))\n",
    "        return self.fc21(h1), self.fc22(h1)\n",
    "\n",
    "    def reparametrize(self, mu, logvar):\n",
    "        std = logvar.mul(0.5).exp_()\n",
    "        eps = torch.FloatTensor(std.size()).normal_()\n",
    "        if torch.cuda.is_available():\n",
    "            eps = Variable(eps.cuda())\n",
    "        else:\n",
    "            eps = Variable(eps)\n",
    "        return eps.mul(std).add_(mu)\n",
    "\n",
    "    def decode(self, z):\n",
    "        h3 = F.relu(self.fc3(z))\n",
    "        return F.tanh(self.fc4(h3))\n",
    "\n",
    "    def forward(self, x):\n",
    "        mu, logvar = self.encode(x) # 编码\n",
    "        z = self.reparametrize(mu, logvar) # 重新参数化成正态分布\n",
    "        return self.decode(z), mu, logvar # 解码，同时输出均值方差\n",
    "\n",
    "net = VAE() # 实例化网络\n",
    "if torch.cuda.is_available():\n",
    "    net = net.cuda()\n",
    "\n",
    "reconstruction_function = nn.MSELoss(size_average=False)\n",
    "\n",
    "def loss_function(recon_x, x, mu, logvar):\n",
    "    \"\"\"\n",
    "    recon_x: generating images\n",
    "    x: origin images\n",
    "    mu: latent mean\n",
    "    logvar: latent log variance\n",
    "    \"\"\"\n",
    "    MSE = reconstruction_function(recon_x, x)\n",
    "    # loss = 0.5 * sum(1 + log(sigma^2) - mu^2 - sigma^2)\n",
    "    KLD_element = mu.pow(2).add_(logvar.exp()).mul_(-1).add_(1).add_(logvar)\n",
    "    KLD = torch.sum(KLD_element).mul_(-0.5)\n",
    "    # KL divergence\n",
    "    return MSE + KLD\n",
    "\n",
    "optimizer = torch.optim.Adam(net.parameters(), lr=1e-3)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 2",
   "language": "python",
   "name": "python2"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
