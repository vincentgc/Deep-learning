# 视角估计
* 利用深度学习来解决视角估计问题（ 本质为图像分类问题）
## code
* DUAN: version 1
* DUAN-v2: version 2, 改进了网络结构和优化函数，载入固定模型参数，加入迁移的效果更明显。（迁移加入新层为4096*512,且两路共享网络参数）（512的考虑是4096直接映射到7可能会有比较大的信息损失）
* model/model_wp1_0.pkl: 预训练模型参数

## 值得注意的点
1. 第一个必须要考虑的问题是深度学习会占用的大量的GPU空间（batch 32会占用将近11G的GPU, batch 16占用约 6G(效果并没有明显的差))， 模型存储也会占用很大的空间（VGG参数占500M）

    **Ps** : 当类别为7，而batch为8时，迁移的效果很差。batch为16时还可以保证效果

2. 第二个要考虑的是深度学习得到的结果是不稳定的，这个和网络初始化和训练方式有关，如何得到稳定的结果还不清楚，只能依靠同样的初始化参数来训练得到相对稳定的结果（但是还是会存在不稳定的情况，也许和优化函数和训练方式有关，待验证）
## 可以改进的点
1. 迁移确实是可行的，但是只验证了虚实场景下的迁移是可行的，不同工件和不同任务下的迁移是不是具有通用性，或者如何做自适应的调整？
2. 参考googlenet和resnet，网络结构是不是可以进一步的优化，来减少参数，同时解决mmd在比较低的层中可能会出现的梯度消失问题？
3. 本工作只是简单的转化成了视角分类问题，并没有考虑视角之间有什么具体的联系。
4. 这个只是简单的深度迁移方式，只是引入了mmd，有没有什么更好的迁移方式。
5. 对于数据来说，只是仿照vgg把输入图像从640x480变为了227x227，这样其实对物体有一个形变。那么如果变为320x240或者其他与原尺寸一致的scale会不会有影响？
6. 还差两类没做。